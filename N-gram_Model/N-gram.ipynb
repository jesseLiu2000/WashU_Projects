{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b6be80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram(word):\n",
    "    words = []\n",
    "    for i in range(len(word)):\n",
    "        words.extend(word[i].split(' '))\n",
    "    unigram = {}\n",
    "    for i in words:\n",
    "        if i not in unigram:\n",
    "            unigram[i] = 1\n",
    "        else:\n",
    "\n",
    "            unigram[i] += 1\n",
    "    \n",
    "    return unigram\n",
    "\n",
    "def bigram(word):\n",
    "    words = []\n",
    "    for i in range(len(word)):\n",
    "        words.extend(word[i].split(' '))\n",
    "    bigram = {}\n",
    "    phrase = []\n",
    "    for i, v in enumerate(words):\n",
    "        if words[i] != '<end>':\n",
    "            com = words[i] +\" \"+ words[i+1]\n",
    "            if com not in bigram:\n",
    "                bigram[com] = 1\n",
    "            else:\n",
    "                bigram[com] += 1\n",
    "\n",
    "    return bigram\n",
    "\n",
    "\n",
    "\n",
    "def trigram(sen):\n",
    "    Trigram = {}\n",
    "    \n",
    "    for i in range(len(sen)):\n",
    "        word = []\n",
    "        word.extend(sen[i].split(\" \"))\n",
    "        for j in range(len(word)-2): \n",
    "            com = word[j] + ' ' + word[j+1] + \" \" + word[j+2]\n",
    "            if com not in Trigram:\n",
    "                Trigram[com] = 1\n",
    "            else:\n",
    "                Trigram[com] += 1 \n",
    "    return Trigram\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "# word = ['<start> I like cola <end>', '<start> I am so happy today <end>', '<start> I like today <end>', '<start> I am so happy today <end>']\n",
    "# word = [\"<start> As the Nameless officially do not exist the upper echelons of the Gallian Army exploit the concept of plausible in order to send them on missions that would otherwise make Gallia lose face in the war While at times this works to their advantage such as a successful incursion into Imperial territory other orders cause certain members of the 422nd great distress One such member becomes so enraged that he abandons his post and defects into the ranks of Calamity Raven attached to the ideal of Darcsen independence proposed by their leader Dahau At the same time elements within Gallian Army Command move to erase the Nameless in order to protect their own interests by both allies and enemies and combined with the presence of a traitor within their ranks the 422nd desperately move to keep themselves alive while at the same time fight to help the Gallian war effort This continues until the Nameless 's commanding officer Ramsey Crowe who had been kept under house arrest is escorted to the capital city of in order to present evidence the weary soldiers and expose the real traitor the Gallian General that had accused Kurt of Treason <end>\", \"<start> due to these events and partly due to the major losses in manpower Gallia suffers towards the end of the war with the Empire the Nameless are offered a formal position as a squad in the Gallian Army rather than serve as an anonymous shadow force This is short lived however as following Maximilian 's defeat Dahau and Calamity Raven move to activate an ancient super weapon within the Empire kept secret by their benefactor Without the support of Maximilian or the chance to prove themselves in the war with Gallia it is Dahau 's last card in creating a new Darcsen nation As an armed Gallian force invading the Empire just following the two nations cease fire would certainly wreck their newfound peace Kurt decides to once again make his squad the Nameless asking Crowe to list himself and all under his command as killed in action Now owing allegiance to none other than themselves the 422nd confronts Dahau and destroys the weapon Each member then goes their separate ways in order to begin their lives <end>\"]\n",
    "# word = ['<start> Life cycle <end>', '<start> Female H. gammarus reach sexual maturity when they have grown to a carapace length of 80 – 85 millimetres 3 @.@ 1 – 3 @.@ 3 in whereas males mature at a slightly smaller size Mating typically occurs in summer between a recently female whose shell is therefore soft and a hard shelled male The female carries the eggs for up to 12 months depending on the temperature attached to her Females carrying eggs are said to be and can be found throughout the year <end>']\n",
    "# count_1 = unigram(word)\n",
    "# count_2 = bigram(word)\n",
    "# count_3 = trigram(word)\n",
    "# print(count_1)\n",
    "# print(count_2)\n",
    "# print(count_3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d607afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate(count_1, count_2, count_3):\n",
    "    sum = 0\n",
    "    for i in count_1:\n",
    "        sum += count_1[i]\n",
    "    pro_unigram = {}\n",
    "    for i in count_1:\n",
    "        pro_unigram[i] = count_1[i] / sum\n",
    "\n",
    "    pro_bigram = {}\n",
    "    for i in count_2:\n",
    "        divid = i.split(\" \")[1]\n",
    "        pro_bigram[i] = count_2[i] / count_1[divid]\n",
    "\n",
    "    \n",
    "    pro_trigram = {} \n",
    "    keys = list(count_3.keys())\n",
    "\n",
    "    cur = []\n",
    "    for i in range(len(keys)):\n",
    "        cur.extend(keys[i].split(\" \"))\n",
    "        com_did = cur[1] + ' ' + cur[2]\n",
    "        divend = count_2[com_did]\n",
    "        par = count_3[keys[i]] / divend\n",
    "        pro_trigram[keys[i]] = par\n",
    "  \n",
    "    return pro_unigram, pro_bigram, pro_trigram\n",
    "        \n",
    "    \n",
    "    \n",
    "# pro_unigram, pro_bigram, pro_trigram = calculate(count_1, count_2, count_3) \n",
    "# print(pro_unigram)\n",
    "# print(pro_bigram)\n",
    "# print(pro_trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a753aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cal_uni_sentence(pro_unigram, pro_bigram, pro_trigram, word):\n",
    "    pro_sentence = {}\n",
    "    for i in word:\n",
    "        pro_sent_uni = 1\n",
    "        word_lst = []\n",
    "        word_lst.extend(i.split(\" \"))\n",
    "        for j in range(len(word_lst)):\n",
    "            pro1 = pro_unigram[word_lst[j]]\n",
    "            pro_sent_uni *= pro1\n",
    "        \n",
    "        pro_sentence[i] = pro_sent_uni\n",
    "    return pro_sentence\n",
    "\n",
    "        \n",
    "def cal_bi_sentence(pro_unigram, pro_bigram, pro_trigram, word):\n",
    "    pro_sentence = {}\n",
    "    for i in word:\n",
    "        pro_sent_uni = 1\n",
    "        word_lst = []\n",
    "        word_lst.extend(i.split(\" \"))\n",
    "        for j in range(len(word_lst)-1):\n",
    "            pro2 = word_lst[j]+\" \" + word_lst[j+1]\n",
    "            pro1 = pro_bigram[pro2]\n",
    "            pro_sent_uni *= pro1\n",
    "        \n",
    "        pro_sentence[i] = pro_sent_uni\n",
    "    return pro_sentence    \n",
    "\n",
    "\n",
    "def cal_tri_sentence(pro_unigram, pro_bigram, pro_trigram, word):\n",
    "    pro_sentence = {}\n",
    "    for i in word:\n",
    "        pro_sent_uni = 1\n",
    "        word_lst = []\n",
    "        word_lst.extend(i.split(\" \"))\n",
    "        for j in range(len(word_lst)-2):\n",
    "            pro2 = word_lst[j]+\" \" + word_lst[j+1] + \" \" + word_lst[j+2]\n",
    "            pro_sent_uni *= pro_trigram[pro2]\n",
    "            pro3 = word_lst[j+1] + \" \" + word_lst[j+2]\n",
    "            \n",
    "        pro_sent_uni *= pro_bigram[pro3]\n",
    "        pro_sentence[i] = pro_sent_uni\n",
    "    return pro_sentence\n",
    "    \n",
    "# uni_pro = cal_uni_sentence(pro_unigram, pro_bigram, pro_trigram, word)\n",
    "# bi_pro = cal_bi_sentence(pro_unigram, pro_bigram, pro_trigram, word)    \n",
    "# tri_pro = cal_tri_sentence(pro_unigram, pro_bigram, pro_trigram, word)\n",
    "# print(uni_pro)\n",
    "# print(bi_pro)\n",
    "# print(tri_pro)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5e2cc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (2.5.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2022.2.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: packaging in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2.27.1)\n",
      "Requirement already satisfied: aiohttp in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: pandas in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.4.2)\n",
      "Requirement already satisfied: dill<0.3.6 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.9.1)\n",
      "Requirement already satisfied: responses<0.19 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: multiprocess in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.21.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: xxhash in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: filelock in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikitext (/Users/liuzijie/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 527.52it/s]\n"
     ]
    }
   ],
   "source": [
    "## your code here\n",
    "!pip install datasets\n",
    "import unicodedata\n",
    "from datasets import list_datasets, load_dataset\n",
    "\n",
    "# Print all the available datasets\n",
    "# print(list_datasets())\n",
    "\n",
    "dataset = load_dataset(\"wikitext\", 'wikitext-2-v1' )\n",
    "# print(data['train'][10:15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82b6165d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (2.5.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2.27.1)\n",
      "Requirement already satisfied: multiprocess in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: dill<0.3.6 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: xxhash in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: pandas in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.4.2)\n",
      "Requirement already satisfied: responses<0.19 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: packaging in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: aiohttp in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.21.5)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2022.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.9.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
      "Requirement already satisfied: filelock in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.9)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/liuzijie/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikitext (/Users/liuzijie/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 734.00it/s]\n"
     ]
    }
   ],
   "source": [
    "## your code here\n",
    "!pip install datasets\n",
    "import unicodedata\n",
    "from datasets import list_datasets, load_dataset\n",
    "import string\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"wikitext\", 'wikitext-2-v1' )\n",
    "# print(data['test'][10:15])\n",
    "\n",
    "            \n",
    "\n",
    "def process_data(wiki_data):\n",
    "    print(wiki_data)\n",
    "    pun = get_punctuation()\n",
    "\n",
    "\n",
    "    pun.add('<unk>')\n",
    "    \n",
    "    print(pun)\n",
    "\n",
    "    vocab = {'pad': 0, '<start>': 1, '<end>': 2}\n",
    "    data = {\"train\": [], \"validation\": [], \"test\": []}\n",
    "\n",
    "    for type in ['test', 'train', 'validation']:\n",
    "        for idx, line in enumerate(wiki_data[type]):\n",
    "            text = line['text'].strip()\n",
    "            words = [i.strip() for i in text.split() if i.strip() not in pun]\n",
    "            if len(words) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                for word in words:\n",
    "                    if word not in vocab:\n",
    "                        vocab[word] = len(vocab)\n",
    "                assert all([i not in ['<start>', '<end>'] for i in words])\n",
    "                words = ['<start>'] + words + ['<end>']\n",
    "                data[type].append(\" \".join(words))\n",
    "\n",
    "    return data, vocab\n",
    "\n",
    "\n",
    "\n",
    "def get_punctuation():\n",
    "    pun = set()\n",
    "    for i in string.punctuation:\n",
    "        pun.add(i)\n",
    "        pun.add('@-@')\n",
    "    \n",
    "    return pun\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbafeea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([1.6075102880658434e-05, 3.34897976680384e-07, 4.8225308641975306e-05])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word = ['<start> I like cola <end>', '<start> I am so happy today <end>', '<start> I like today <end>', '<start> I am so happy today <end>']\n",
    "\n",
    "\n",
    "count_1 = unigram(word)\n",
    "count_2 = bigram(word)\n",
    "count_3 = trigram(word)\n",
    "\n",
    "pro_unigram, pro_bigram, pro_trigram = calculate(count_1, count_2, count_3) \n",
    "\n",
    "uni_pro = cal_uni_sentence(pro_unigram, pro_bigram, pro_trigram, word)\n",
    "bi_pro = cal_bi_sentence(pro_unigram, pro_bigram, pro_trigram, word)    \n",
    "tri_pro = cal_tri_sentence(pro_unigram, pro_bigram, pro_trigram, word)\n",
    "\n",
    "print(uni_pro.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8263a5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<start> I like cola <end>': 19.725021954206714, '<start> I am so happy today <end>': 8.414193527290326, '<start> I like today <end>': 19.725021954206714}\n",
      "{'<start> I like cola <end>': 1.148698354997035, '<start> I am so happy today <end>': 1.1040895136738123, '<start> I like today <end>': 1.148698354997035}\n",
      "{'<start> I like cola <end>': 1.0592238410488122, '<start> I am so happy today <end>': 1.0419536274372085, '<start> I like today <end>': 1.0592238410488122}\n"
     ]
    }
   ],
   "source": [
    "## your code here\n",
    "import math\n",
    "uni_pro = cal_uni_sentence(pro_unigram, pro_bigram, pro_trigram, word)\n",
    "bi_pro = cal_bi_sentence(pro_unigram, pro_bigram, pro_trigram, word)    \n",
    "tri_pro = cal_tri_sentence(pro_unigram, pro_bigram, pro_trigram, word)\n",
    "# uni_list = list(uni_pro.keys())\n",
    "def cal_perplexity(pro):\n",
    "    keys_list = list(pro.keys())\n",
    "    perplesity = {}\n",
    "    for i in range(len(keys_list)):\n",
    "        voc = []\n",
    "        voc.extend(keys_list[i].split(\" \"))\n",
    "        num = len(voc)\n",
    "        if(pro[keys_list[1]]==0):\n",
    "          p = 0\n",
    "        else:\n",
    "          p = math.pow(1 / pro[keys_list[1]], 1/num)\n",
    "        perplesity[keys_list[i]] = p\n",
    "    return perplesity\n",
    "\n",
    "Uni_perplesity = cal_perplexity(uni_pro)\n",
    "Bi_perplesity = cal_perplexity(bi_pro)\n",
    "Tri_perplesity = cal_perplexity(tri_pro)\n",
    "print(Uni_perplesity)\n",
    "print(Bi_perplesity)\n",
    "print(Tri_perplesity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b55ee055",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here\n",
    "uni_pro = cal_uni_sentence(pro_unigram, pro_bigram, pro_trigram, word)\n",
    "bi_pro = cal_bi_sentence(pro_unigram, pro_bigram, pro_trigram, word)    \n",
    "tri_pro = cal_tri_sentence(pro_unigram, pro_bigram, pro_trigram, word)\n",
    "\n",
    "def calculate_laplace(count_1, count_2, count_3):\n",
    "    sum = 0\n",
    "    for i in count_1:\n",
    "        sum += count_1[i]\n",
    "    pro_unigram = {}\n",
    "    for i in count_1:\n",
    "        pro_unigram[i] = count_1[i] + 1 / sum + len(vocab)\n",
    "    \n",
    "    pro_bigram = {}\n",
    "    for i in count_2:\n",
    "        divid = i.split(\" \")[1]\n",
    "        pro_bigram[i] = count_2[i] + 1 / count_1[divid] + len(vocab)\n",
    "\n",
    "    pro_trigram = {} \n",
    "    keys = list(count_3.keys())\n",
    "\n",
    "    cur = []\n",
    "    for i in range(len(keys)):\n",
    "        cur.extend(keys[i].split(\" \"))\n",
    "        com_did = cur[1] + ' ' + cur[2]\n",
    "        divend = count_2[com_did]\n",
    "        par = count_3[keys[i]] + 1 / divend + len(vocab)\n",
    "        pro_trigram[keys[i]] = par\n",
    "    \n",
    "    return pro_unigram, pro_bigram, pro_trigram\n",
    "\n",
    "\n",
    "  \n",
    "def calculate_addK(K, count_1, count_2, count_3):\n",
    "    sum = 0\n",
    "    for i in count_1:\n",
    "        sum += count_1[i]\n",
    "    pro_unigram = {}\n",
    "    for i in count_1:\n",
    "        pro_unigram[i] = count_1[i] + K / sum + K * 24\n",
    "\n",
    "    \n",
    "    pro_bigram = {}\n",
    "    for i in count_2:\n",
    "        divid = i.split(\" \")[1]\n",
    "        pro_bigram[i] = count_2[i] + K / count_1[divid] + K * 24\n",
    "\n",
    "    \n",
    "    pro_trigram = {} \n",
    "    keys = list(count_3.keys())\n",
    "\n",
    "    cur = []\n",
    "    for i in range(len(keys)):\n",
    "        cur.extend(keys[i].split(\" \"))\n",
    "        com_did = cur[1] + ' ' + cur[2]\n",
    "        divend = count_2[com_did]\n",
    "        par = count_3[keys[i]] + K / divend + K * 24\n",
    "        pro_trigram[keys[i]] = par\n",
    "    \n",
    "    return pro_unigram, pro_bigram, pro_trigram\n",
    "\n",
    "\n",
    "# pro_unigram, pro_bigram, pro_trigram = calculate_laplace(count_1, count_2, count_3) \n",
    "\n",
    "# pro_unigram, pro_bigram, pro_trigram = calculate_addK( 0.1, count_1, count_2, count_3) \n",
    "# pro_unigram, pro_bigram, pro_trigram = calculate_addK( 0.05, count_1, count_2, count_3) \n",
    "# pro_unigram, pro_bigram, pro_trigram = calculate_addK( 0.01, count_1, count_2, count_3) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a21bdee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<start> I like cola <end>': 19.725021954206714, '<start> I am so happy today <end>': 8.414193527290326, '<start> I like today <end>': 19.725021954206714}\n",
      "{'<start> I like cola <end>': 1.148698354997035, '<start> I am so happy today <end>': 1.1040895136738123, '<start> I like today <end>': 1.148698354997035}\n",
      "{'<start> I like cola <end>': 1.0592238410488122, '<start> I am so happy today <end>': 1.0419536274372085, '<start> I like today <end>': 1.0592238410488122}\n"
     ]
    }
   ],
   "source": [
    "uni_pro = cal_uni_sentence(pro_unigram, pro_bigram, pro_trigram, word)\n",
    "bi_pro = cal_bi_sentence(pro_unigram, pro_bigram, pro_trigram, word)    \n",
    "tri_pro = cal_tri_sentence(pro_unigram, pro_bigram, pro_trigram, word)\n",
    "\n",
    "\n",
    "Uni_perplesity = cal_perplexity(uni_pro)\n",
    "Bi_perplesity = cal_perplexity(bi_pro)\n",
    "Tri_perplesity = cal_perplexity(tri_pro)\n",
    "print(Uni_perplesity)\n",
    "print(Bi_perplesity)\n",
    "print(Tri_perplesity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
