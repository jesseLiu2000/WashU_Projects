# N-gram-Model
Here I achieve n-gram(unigram, bigram, trigram) model and then can apply it in the input sentence to calculate the probability </br>
I also calculate perplexity for every sentence in our corpus and more, I use the add-K (K=1, 0.05, 0.01, 0.1) smoothing and apply this method on every n-gram model.</br>
Here for the dataset, I use the 'wikitext-2-v1'
